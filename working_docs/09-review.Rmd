# Denouement

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, rows.print=5, fig.width=9)
```

In this lesson you will take all of the skills you have learned up to this point and use them on a completely new set of data.

#### Necessary packages:

```{r}
library(tidyverse)
library(rstatix)
# library(scales)
library(httr)
library(jsonlite)
library(dataRetrieval)
library(sf) # for the map
library(mapview) # for making the interactive plot
```

## Tidying datasets

We are interested in looking at how the Cache la Poudre River's flow changes as it travels out of the mountainous Poudre Canyon and through Fort Collins.

There are four stream flow monitoring sites on the Poudre that we are interested in: two managed by the US Geological Survey (USGS), and two managed by the Colorado Division of Water Resources (CDWR):

```{r, echo = F}
# Making a tibble to convert into coordinates for our sites
poudre_sites <- tibble(site = c("Canyon Mouth", "Lincoln Bridge", "Environmental Learning Center", "Below Fossil Creek Reservoir"),
                       site_no = c("CLAFTCCO", "06752260", "06752280", "CLARIVCO"),
                       lat = c(40.6645, 40.5880833, 40.5519269, 40.5013),
                       long = c(-105.2242, -105.0692222, -105.011365, -104.967),
                       source = c("CDWR", "USGS", "USGS", "CDWR")) %>%
  sf::st_as_sf(coords = c("long", "lat"), crs = 4269)

# Mapview is another package that creates interactive plots, not necessary for you to know yet! More in 523a :-)
mapview::mapview(poudre_sites, zcol = "site_no", layer.name = "Poudre River Monitoring")
```

### USGS `dataRetrieval` R package

To pull data for USGS stream gages, we can use the `dataRetrieval` package, which is a USGS-managed set of functions that, much like our functions from Lesson 3.1, pull data from the USGS's data warehouse using an API. Here we will pull flow data for our USGS stream gages of interest for two water years:

```{r}
# pulls USGS daily ('dv') stream flow data:
usgs <- dataRetrieval::readNWISdv(siteNumbers = c("06752260", "06752280"), # USGS site code for the Poudre River at the Lincoln Bridge and the ELC
                                  parameterCd = "00060", # USGS code for stream flow
                                  startDate = "2020-10-01", # YYYY-MM-DD formatting
                                  endDate = "2022-09-30") %>% # YYYY-MM-DD formatting
  rename(q_cfs = X_00060_00003) %>% # USGS code for stream flow units in cubic feet per second (CFS)
  mutate(Date = lubridate::ymd(Date), # convert the Date column to "Date" formatting using the `lubridate` package
         Site = case_when(site_no == "06752260" ~ "Lincoln", 
                          site_no == "06752280" ~ "Boxelder"))
```

### CDWR's API

Alas, CDWR does NOT have an R package that pulls data from [their API](https://dwr.state.co.us/Rest/GET/Help#Datasets&#SurfaceWaterController&#gettingstarted&#jsonxml), but they do have user-friendly directions on how to develop API calls.

Using the "URL generator" steps outlined for their [daily surface water time series data set](https://dwr.state.co.us/Rest/GET/Help/SurfaceWaterTSDayGenerator), we can get the last two water years of CFS data for the Poudre at the Canyon mouth (site abbreviation = CLAFTCCO) using the following URL:

<https://dwr.state.co.us/Rest/GET/api/v2/surfacewater/surfacewatertsday/?format=json&dateFormat=dateOnly&fields=abbrev%2CmeasDate%2Cvalue%2CmeasUnit&encoding=deflate&abbrev=CLAFTCCO&min-measDate=10%2F01%2F2020&max-measDate=09%2F30%2F2022>

Using the URL above as the starting point, we can develop a function that creates a data frame of CDWR daily flow (CFS) data for a selected range of water years, for any site. 

```{r}
# (Something we will learn in 523a!) Don't fear if you do not understand this.
co_water_data <- function(site, start_year, end_year){
  
  raw_data <- httr::GET(url = paste0("https://dwr.state.co.us/Rest/GET/api/v2/surfacewater/surfacewatertsday/?format=json&dateFormat=dateOnly&fields=abbrev%2CmeasDate%2Cvalue%2CmeasUnit&encoding=deflate&abbrev=",site,
                                     "&min-measDate=10%2F01%2F", start_year - 1,
                                     "&max-measDate=09%2F30%2F", end_year))
  
  extracted_data <- httr::content(raw_data, as = "text", encoding = "UTF-8") 
  
  # parse text from JSON to data frame
  final_data <- jsonlite::fromJSON(extracted_data)[["ResultList"]]
  
  return(final_data)
  
}
```

Now that we have a function for pulling in CDWR data, we can map over it to pull flow data for CLAFTCCO and CLARIVCO for the 2021 and 2022 water years.

```{r}
sites <- c("CLAFTCCO","CLARIVCO")

cdwr <- sites %>% map(~ co_water_data(site = ., start_year = 2021, end_year = 2022)) %>%
  bind_rows() %>%
  rename(q_cfs = value) %>%
  mutate(Date = lubridate::ymd(measDate),
         Site = ifelse(abbrev == "CLAFTCCO", "Canyon",
                       "Timnath"))
```

Next, we can join our USGS and CDWR data frames together with `bind_rows()`.

```{r}
data <- bind_rows(usgs,cdwr)
```

## Exploratory Data Analysis

Let's explore the data to see if there are any trends we can find visually. We can first visualize the data as time series:

```{r}
# Discharge (in CFS) through time displaying all four of our monitoring sites.
  ggplot(data = data) +
                   geom_line(aes(x=Date, y=q_cfs, color = Site)) +
                   theme_bw() +
                   xlab("Date") +
                   ylab("Discharge (cfs)") +
                   facet_wrap(~Site, ncol=1)

# OR #

  ggplot(data = data) +
    geom_line(aes(x=Date, y=q_cfs, color = Site)) +
    xlab("Date") +
    ylab("Discharge (cfs)") +
    theme_bw()
```

Next we can visualize the spread of flows across each site, looking at site summaries with a `geom_boxplot()`:

```{r}  
data %>% 
  ggplot(aes(x = Site, y = q_cfs, color = Site)) + 
  geom_boxplot()
```

We can create a plot of the daily difference in discharge between the Cache la Poudre River at the canyon mouth and each of the sites downstream. This will require some rearranging of our data using `pivot_wider()`:

```{r}
new_data <- data %>%
  select(Site, Date, q_cfs) %>%
  pivot_wider(., names_from = Site, values_from = q_cfs) %>%
  mutate_at(.vars = c("Boxelder", "Lincoln", "Timnath"), .funs = ~ (Canyon - .)) %>%
  pivot_longer(-c(Canyon, Date))

  ggplot(data = new_data) +
    geom_line(aes(x = Date, y = value, color = name)) +
    theme_bw() +
    ylab("Canyon - Site")
```

## Data Analysis

Through our exploratory data analysis, it *appears* that stream flow decreases as we move through town. But, how can we test if these flows are significantly different, and identify the magnitude/direction of these differences?

Because we will be comparing daily stream flow across multiple sites, we can use an ANOVA test to assess this research question. We will set our alpha at 0.05.

### Testing for normal distibution

ANOVA assumes normal distribution within each group - we can visualize each site's data with a histogram:

```{r}
ggplot(data = data, aes(x = q_cfs)) +
         geom_histogram() + 
  facet_wrap (~Site)
```

... and use the `shapiro_test()` function along with `group_by()` to statisticaly test for normality within each site's daily stream flow data:

```{r}
data %>%
  group_by(Site) %>%
  shapiro_test(q_cfs)
```

Since the null hypothesis of the Shapiro-Wilk test is that the data is normally distributed, these results tell us all groups do not fit a normal distribution for daily stream flow. It is also quite clear from their histograms that they are not normally distributed.

### Testing for equal variance

To test for equal variances among more than two groups, it is easiest to use a Levene's Test like we have done in the past:

```{r}
data %>%
  levene_test(q_cfs ~ Site)
```

Given this small p-value, we see that the variances of our groups are not equal.

### ANOVA - Kruska-Wallis

After checking our assumptions we need to perform a non-parametric ANOVA test, the Kruskal-Wallis test.

```{r}
data %>%
  kruskal_test(q_cfs ~ Site)
```

Our results here are highly significant (at alpha = 0.05), meaning that at least one of our groups's mean stream flow is significantly different from the others.

### ANOVE post-hoc analysis

Since we used the non-parametric Kruskal-Wallace test, we can use the associated Dunn's test to test across our sites for significant differences in mean stream flow:

```{r}
data %>% 
  dunn_test(q_cfs ~ Site)
```

The results of our Dunn test signify that the mean streamflow across our sites are significantly different. 

THOUGHT EXPERIMENT 1: Based on our results, which of our two gages have the greatest difference in mean daily stream flow?

THOUGHT EXPERIMENT 2: Is this an appropriate test to perform on stream flow data? Why or why not?