# Data Analysis: T-test and ANOVA

```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE)
```

In this lesson you will be introduced to the process of conducting statistical tests in R, specifically t-tests and ANOVA tests for working with categorical predictor variables.

First, to access the dataset(s) you will be using in this lesson, we will be using a new data packages called [{lterdatasampler}](https://lter.github.io/lterdatasampler/). This packages contains subsets of data from various Long Term Ecological Research (LTER) sites, designed for use in R teaching and training activities.

So since this is a new package, we need to install it first:

```{r eval=FALSE}
install.packages("lterdatasampler")
```

Now load in the two libraries needed for this lesson (OR, add `lterdatasampler` to your 'setup.R' script if you have been setting up your environment that way).

```{r}
library(tidyverse)
library(lterdatasampler)
```

Then run the following line of code to retrieve the `and_vertebrates` data set and bring it into your R session:

```{r}
data(and_vertebrates)
```

## Explore the dataset

Do a little exploration of this data first to understand its structure, variables and data types:

```{r eval=FALSE}
# View the data structure
glimpse(and_vertebrates)

# Explore the metadata in the Help pane
?and_vertebrates
```

This data set contains length and weight observations for three aquatic species in clear cut and old growth coniferous forest sections of Mack Creek in HJ Andrews Experimental Forest in Oregon. The three species are **Cutthroat trout**, **Coastal giant salamander** and **Cascade torrent salamander**.

## t-test - Compare two means

Previous work has shown that forest harvesting can impact aquatic vertebrate biomass (Kaylor & Warren 2017). With this `and_vertebrates` data set we can investigate this hypothesis, by comparing weight to forest type (clear cut or old growth). This therefore involves a test comparing the means (average weight) among two groups (clear cut and old growth forests), which then requires a t-test.

Lets focus on conducting this test for just Cutthroat trout to reduce species-level variances in weight. Before conducting analyses, we need to clean our dataset. The steps below will filter our data to just include the trout species, and remove any NA values of weight with the `drop_na()` function:

```{r}
#create a new variable for downstream analysis
trout_clean <- and_vertebrates %>% 
  #filter species (remember spelling and capitalization are IMPORTANT)
  filter(species == "Cutthroat trout") %>% 
  # remove NA values for weight
  drop_na(weight_g)
  
```

Before conducting any analsys, we may want to **visualize** the relationship between forest type and weight, which we can do with a boxplot given we have a categorical predicator variable (forest type, aka `section`) and a continuous response variable (`weight_g`).

```{r}
trout_clean %>%
  ggplot(aes(x = section, y = weight_g)) +   
  geom_boxplot()
```

We don't see too much of a difference based on this visual, but lets conduct the statistical test to verify if our hypothesis is supported.

### Assumptions

First however we need to check our test assumptions, which for t-tests assumes the **variance of the groups is equal**. We can test for equal variances with the function `var.test()`, where the *null* hypothesis is that the variances are equal. In this step we need two vectors of the weights in each separate forest section. You can use `pull()` to convert a single column of a data frame/tibble to a vector, and we want to do this for clear cut and old growth forests separately. We then put both of those vectors in the `var.test()` function to assess their equal variances.

```{r}
# numeric vector of just the weight values for CC forests
cc_weight <- 
  trout_clean %>%    
  filter(section == "CC") %>%    
  pull(weight_g)  

# numeric vector of just the weight values for OG forests
og_weight <- 
  trout_clean %>%    
  filter(section == "OG") %>%    
  pull(weight_g)  

# test for equal variance among the two sets of numbers
var.test(cc_weight, og_weight)
```

Looks like our variances are **not equal,** since the null hypothesis of the variance test is that they are equal and we have a (very) significant p-value. We have two options now, **1)** we can transform our weight variable or **2)** use the Welch t-test which does not assume equal variances.

#### **Variable transformation**

If we look at the distribution of weight (our continuous variable), it is pretty right skewed. Therefore, we'd likely want to do a log transformation on the data, which works well the data is skewed like this:

```{r}
hist(trout_clean$weight_g)
```

Lets perform the variances check like we did before, but on the log transformed values, which you can do with `log()` , and we can nest the functions so we only use one line of code like this:

```{r}
var.test(log(cc_weight), log(og_weight))
```

Now we have a high, insignificant p-value, indicating support for the null that the variances are equal. So. we can use the default `t.test()` test which assumes equal variances, but on a log transformed weight variable.

The `t.test()` function in R takes in your dependent (in our case trout weight) and independent (forest type) variables as vectors (instead of just column names like you can do in the Tidyverse). Remember how we can index single columns of data frames with the `$` operator (this is why we learn Base R too!). The order of the variables in the `t.test()` function is **{dependent variable} \~ {independent variable}**. We use the `~` to specify a model, telling the test we want to know if weight *varies by* forest section.

Remember we also want to log transform the weight values and then specify that our variances are equal since we confirmed that with `var.test()` above, so the final `t.test()` call would be this:

```{r}
t.test(log(trout_clean$weight_g) ~ trout_clean$section, var.equal = TRUE)
```

The output of this test gives us the test statistics, p-value, and the means for each of our forest groups. Given the p-value of 0.0043 and the means of each gorup, we can conclude that *Cutthroat trout weight was observed to be significantly higher in clear cut forests compared to old growth forests*. Remember though that now these mean weight values are log transformed, and not the raw weight in grams. The relationship can still be interpreted the same.

How does this relate to your original hypothesis?

**Welch Two Sample t-test**

Alternatively, instead of transforming our variable we can actually change the default `t.test()` argument by specifying `var.equal = FALSE`, which will then conduct a Welch t-test, which does not assume equal variances among groups.

```{r}
t.test(trout_clean$weight_g ~ trout_clean$section, var.equal = FALSE) 
```

While we used a slightly different method, our conclusions are still the same, finding that Cutthroat trout had significantly higher weights in clear cut forests than old growth.

::: {.alert .alert-info}
Note: In the `t.test()` function you can add `paired = TRUE` to conduct a paired t-test. These are for cases when the groups are 'paired' for each observation, meaning each group/treatment was applied to the same individual, such as before and after experiments.
:::

## ANOVA test - compare more than two means

We found a significant difference in weight among forest types, but how about channel types? The `unittype` variable is categorical like `section` was, but here we have more than two categories. With more than two categories we use an ANOVA test instead of a t-test to assess significant differences in some continuous variable among groups.

Let's first look at the distribution of trout samples among different channel types:

```{r}
trout_clean %>% 
  group_by(unittype) %>% 
  count()
```

We see there are quite a few samples with missing information for channel type. Let's remove those values before our analysis, and save those results to a new variable so as not to override the data we used for the previous analysis (as we could be remove observations that were included in the t-test).

Also, there are some groups that have relatively low sample size. For the sake of this lesson, lets just keep the four most abundant channel types, i.e. C (cascade), P (pool), and SC (side channel).

```{r}
trout_clean_unit <- trout_clean %>% 
  # note this line of code is the same as doing filter(!is.na(unittype))
    drop_na(unittype) %>% 
    filter(unitt)
  
```

### Assumptions

***Normality***

ANOVA assumes normal distributions within each group. Here our group sample sizes are \~30 each which can be considered as large enough to not worry about this assumption, but lets walk through how to statistically check for normality if you had smaller sample sizes.

You could test for normality with the Shaprio-Wilk test for each group individually, but here we have a lot of groups (13) and that would be tedious. Instead, we can calculate the residuals for all groups and test for normal distribution on the single set of residuals.

::: {.alert .alert-info}
A residual value is computed for each observation as the difference between that value and the mean of all values for that group.
:::

We can get the residuals from the ANOVA model by running `aov()`. To carry out the ANOVA model, we specify the name of our continuous response (size) \~ the name of our categorical predictor (site), and specify the data set name. *Note that the `aov()` function won't work the `%>%` pipe.*

```{r} res_aov <- aov(size ~ site, data = pie_crab)}
```

We can then pull out the residuals of this `aov()` model like we do by indexing columns with the `$` operator. Let's check the distribution visually with `hist()` and then statistically with `shapiro.test()`.

```{r} hist(res_aov$residuals)  shapiro.test(res_aov$residuals)}
```

This returns a p-value of 0.72, so we accept the null that this data **does** fit the normal distribution assumption.

***Equal Variances***

To test for equal variances among more than two groups, it is easiest to use a Levene's Test. To use this test we need to install a new package called `car`, which you should have done at the beginning of this lesson.

```{r} leveneTest(size ~ site, data = pie_crab)}
```

Similar to the `var.test()` function you've used before, the *null hypothesis* of the Levene's test is that the variances *are* *equal*. Given this small p-value (denoted the the 'Pr(\>F)' value) we see that the variances of our groups are not equal.

Therefore we would have to perform a Welch ANOVA:

```{r} oneway.test(size ~ site, data = pie_crab, var.equal = FALSE)}
```

Our results here are highly significant, meaning that at least one of our groups means is significantly different from the others.

Now ANOVAs don't tell us which groups are significantly different, for that we would need to use the post-hoc Tukey's HSD test.

However for 13 groups that is a lot of pairwise comparisons to perform. For the next example lets filter our analysis to check for differences among 3 sites, choosing sites at the two extremes in latitude and one in the middle of the range.

```{r} pie_sites <- pie_crab %>%    filter(site %in% c("GTM", "DB", "PIE"))}
```

We already know that this data set fits the normality assumption, but now lets check if the variances of these 3 sites are equal or not.

```{r} leveneTest(size ~ site, data = pie_sites)}
```

A p-value of 0.58 is much higher than our cut-off of 0.05, so we are confident that the variances are equal and we can therefore carry out the ANOVA with the `aov()` as we meet all its assumptions.

```{r} pie_anova <- aov(size ~ site, data = pie_sites)}
```

To view the ANOVA results of this model we use `summary()`

```{r} summary(pie_anova)}
```

### Post-hoc Tukey's HSD test

From the ANOVA test we find that at least one of our group means is significantly different from the others. Now we can use the `TukeyHSD()` function to test all the pairwise differences to see which groups are different from each other.

```{r} TukeyHSD(pie_anova)}
```

This returns each combination of site comparisons and a p-value (the 'p adj' variable) for each.

This returns just about the same data frame as the first method, but now with the NA category removed because it dropped any observations that were `NA` for `unittype`.

From this we also observe that the highest Cutthroat trout abundances are found in cascade (C), pool (P), and side channel (SC) habitats.

Now, our question expands beyond this one categorical variable (channel type) and we want to know if abundance is affected by both channel and and forest type (`section`). Here, *our null hypothesis is that forest and channel type are independent*. To test this, we use the `chisq.test()` function to carry out a chi-square test, but first we have to reformat our data into a **contingency table**.

A contingency table is in matrix format, where each cell is the frequency (in this case seen as abundance) of Cutthroat trout in each combination of categorical variables (forest type and channel unit). We can create a contingency table with the `table()` function. For this analysis, lets also filter out just the 3 most abundant unit types for Cutthroat trout (C, P and SC).

```{r}
# First clean the dataset to create the contingency table from
trout_clean <- and_vertebrates %>% 
  #filter Cutthroat trout
  filter(species == "Cutthroat trout") %>% 
  # lets test using just the 3 most abundant unittypes
  filter(unittype %in% c("C", "P", "SC")) %>% 
  # drop NAs for both unittype and section
  drop_na(unittype, section)
```

Looking at these results, we have an extremely small p-value. This tells us that there *is* a significant relationship between forest type and channel unit (i.e., we rejected our null hypothesis).

Lets look at the abundance distribution visually:

```{r}
trout_clean %>% 
  count(unittype, section) %>% 
  ggplot(aes(x = unittype, y = n))+
  geom_col(aes(fill = section))+
  scale_fill_manual(values = c("orange", "darkgreen"))+
  theme_minimal()
```

## Exercises

Each question requires you to carry out a statistical analysis to test some hypothesis related to the `and_vertebrates` data set. To answer each question fully:

-   Include the code you used to clean the data and conduct the appropriate statistical test. (*Including the steps to assess and address your statistical test assumptions*).

-   Report the findings of your test in proper scientific format (with the p-value in parentheses).

<br>

**1.** Conduct a chi-square test similar to the one we carried out earlier in this lesson plan, but test for a relationship between forest type (`section`) and channel unit (`unittype`) for *Coastal giant salamander* abundance. *Keep all unittypes* instead of filtering any like we did for the Cutthroat trout (9 pts.)

<br>

**2.** Test the hypothesis that there is a significant difference in species biomass between clear cut and old growth forest types for the *Coastal Giant salamander*. (8 pts.)

<br>

**3.** Test the correlation between body length (snout to fork length) and body mass for *Cutthroat trout*. (Hint: run `?and_vertebrates` to find which length variable represents snout to fork length) (8 pts.)

<br> <br>

### Acknowledgements

Thanks to the developers of [`lterdatasampler`](https://lter.github.io/lterdatasampler/index.html) for providing the data set and vignettes that helped guide the creation of this lesson plan.

### Citations

***Data Source:*** Gregory, S.V. and I. Arismendi. 2020. Aquatic Vertebrate Population Study in Mack Creek, Andrews Experimental Forest, 1987 to present ver 14. Environmental Data Initiative. <https://doi.org/10.6073/pasta/7c78d662e847cdbe33584add8f809165>

Kaylor, M.J. and D.R. Warren. 2017. Linking riparian shade and the legacies of forest management to fish and vertebrate biomass in forested streams. Ecosphere *8*(6). <https://doi.org/10.1002/ecs2.1845>

# Multivariate Statistics

In this lesson you will be introduced to statistical tests for dealing with more complex data sets, such as when you need to compare across more than two groups (ANOVA) or assess relationships in the form of an equation to predict response variables given single or multiple predictors (Regression).

First you'll need to load in the libraries and data set for the lesson.

We need to install one new package for today to use a specific statistical test. This package is called `car`. Follow the steps below to install the package, and then read in your libraries and data set for the lesson.\

```{r eval = FALSE}
#install the car package
install.packages("car")

```

```{r}
#load in packages
library(tidyverse)
library(lterdatasampler)
library(car)

# data set
data("pie_crab")
```

## Explore the Data set

This data set consists of Fiddler crab body size measured in salt marshes from Florida to Massachusetts during summer 2016 at Plum Island Ecosystem LTER.

```{r}
glimpse(pie_crab)
```

Learn more about each variable:

```{r}
?pie_crab
```

This data set provides a great opportunity to explore Bergmann's rule: where organisms at higher latitudes are larger than those at lower latitudes. There are various hypotheses on what drives this phenomenon, which you can read more about in [Johnson et al. 2019](https://onlinelibrary.wiley.com/doi/10.1002/ece3.5883).

We have a continuous size variable (carapace width in mm), our dependent variable, and various predictor variables: site (categorical), latitude (continuous), air temperature (continuous) and water temperature (continuous).

Let's explore the sample size at each site and how many sites are in this data set

```{r}
# sample size per site
pie_crab %>% 
  group_by(site) %>% 
  count()

```

We have 13 sites with \~30 individual male crabs measured at each site.

Let's also check the range of our continuous variables:

```{r}
summary(pie_crab)
```

## ANOVA

First we can see if there is a significant difference in crab size among sites. Since we have a continuous response variable (size) and a categorical predictor (site) with \> 2 groups (13 sites), we will use an ANOVA test.

Lets first visualize the distribution of size values for each site using a new visualization technique with ggplot called `geom_jitter()`. This function adds a small amount of variation to each point, so that all our points for each site are not stacked on top of each other (*for example, try running the following code below but with `geom_point()` instead of `geom_jitter()` and notice the difference*).

In this code we also use the `reorder()` function to order our x axis value (site) by latitude to see any initial trends fitting Bergmann's rule.

```{r}
pie_crab %>% 
  ggplot(aes(x = reorder(site, latitude), y = size, color = site)) + 
  geom_jitter()+
  # edit y axis label
  labs(x = "", y = "Carapace width (mm)")+
  # remove the legend and x axis label
  theme(legend.position = "none",
        axis.title.x = element_blank())
```

Looks like there is variation among sites, so lets test for statistical significance with the ANOVA test.

## Simple Linear Regression

Lets more directly test Bergmann's rule by testing for a relationship between carapace width and latitude. Since our predictor (latitude) is a continuous, quantitative variable, we can conduct a simple linear regression.

To conduct a regression model, we use the `lm()` function.

```{r}
pie_lm <- lm(size ~ latitude, data = pie_crab)

#view the results of the linear model
summary(pie_lm)
```

Our p-value is indicated in the 'Pr(\>\|t\|)' column for 'latitude' and at the bottom of these results, telling us that latitude does have a significant effect on crab size.

From the results we also have an Estimate for latitude (0.49), which reflects the regression coefficient or strength and direction of the effect of latitude, along with the standard error for that estimate (0.03), reflecting the variation in that estimate.

Lets view this visually and fit the linear regression line of best fit.

```{r}
pie_crab %>% 
  ggplot(aes(x = latitude, y = size))+
  geom_point()+
  geom_smooth(method = "lm")

```

Now that we fit this model, we can use it to predict crab size at different latitudes with `predict()`. For example, lets predict carapace width at a latitudes of 32, 36, and 38 degrees. Note that we need to create these values as a new data frame with the same column name used in the data that the model was built of off.

```{r}
new_lat <- data.frame(latitude = c(32, 36, 38))

predict(pie_lm, newdata = new_lat)
```

## Multiple Linear Regression

Say we want to model the effect of more than one predictor on crab size. In this data set we also have continuous variables for air temperature and water temperature. Lets model the effect of latitude, air and water temperature on carapace width.

Running a multiple linear regression is very similar to the simple linear regression, but now we specify our multiple predictor variables by adding them together with a `+` sign like this:

```{r}
pie_mlm <- lm(size ~ latitude + air_temp + water_temp, data = pie_crab)

summary(pie_mlm)
```

These results show an overall p-value for the model, indicating a significant impact of the combination of predictor variables on crab size, and individual p-values for the effect of each individual predictor on crab size.

Note however that normally with multiple regression, one of the assumptions is that there is no correlation between the predictor variables. We can test for correlations between more than two variables with the `cor()` function. Lets test for correlation between our three predictors:

```{r}
pie_crab %>% 
  select(latitude, air_temp, water_temp) %>% 
  cor()
```

Normally tests remove variables that have a correlation coefficient greater than 0.7/-0.7. These are all highly correlated (with coefficients near 1/-1), therefore probably not the best set of predictors to use for a multiple linear regression. Below in your assignment you will perform a multiple linear regression using variables that are a bit less correlated.

## Exercises

1.  **After** completing the ANOVA test (and post-hoc Tukey's HSD) in **section 6.2** to test for significant differences in crab size among 3 different sites: **1)** Create a boxplot showing the carapace width for each site where sites are *ordered by latitude* and **2)** report the findings of the statistical test as you would in a scientific paper. *Include both the code to create the boxplot and an image of the figure.* (6 pts.)

2.  Conduct a simple linear regression for the effect of `water_temp_sd` (a measure reflecting annual variation in water temperature) on carapace width. Report your findings (include code *and* a sentence reporting the results) AND create a plot with a line of best fit. *Include both the code to create the plot and an image of the figure*. (10 pts).

3.  Conduct a multiple linear regression for the effects of `latitude`, `air_temp_sd`, and `water_temp_sd` on carapace width. **First** check for correlations among the three predictor variables (and report the correlation table) and **second** report your findings from the multiple linear regression (code *and* a sentence reporting the results). (9 pts.)

### Acknowledgements

Thanks to the developers of [`lterdatasampler`](https://lter.github.io/lterdatasampler/index.html) for providing the data set and vignettes that helped guide the creation of this lesson plan.

### Citations

-   Johnson, D. 2019. Fiddler crab body size in salt marshes from Florida to Massachusetts, USA at PIE and VCR LTER and NOAA NERR sites during summer 2016. ver 1. Environmental Data Initiative. <https://doi.org/10.6073/pasta/4c27d2e778d3325d3830a5142e3839bb> (Accessed 2021-05-27).

-   Johnson DS, Crowley C, Longmire K, Nelson J, Williams B, Wittyngham S. The fiddler crab, Minuca pugnax, follows Bergmann's rule. Ecol Evol. 2019;00:1--9. <https://doi.org/10.1002/ece3.5883>
